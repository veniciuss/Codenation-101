{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WIiv8dWEFm0Z"
   },
   "outputs": [],
   "source": [
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import max_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import warnings\n",
    "#warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BPEdfslOFm0f"
   },
   "outputs": [],
   "source": [
    "#Returns null values (%)\n",
    "def get_nans(df):\n",
    "    nan_dic = {}\n",
    "    for col in df.columns:\n",
    "        if df[col].isnull().any() == True:\n",
    "            nan_dic[col] = df[col].isnull().sum()\n",
    "    return pd.DataFrame({\n",
    "        'Feature': list(nan_dic.keys()),\n",
    "        'Nulls': list(nan_dic.values()),\n",
    "        'Percent': np.round((np.array(list(nan_dic.values())) / df.shape[0])*100, decimals = 1)\n",
    "    }).sort_values('Nulls',ascending = False)\n",
    "\n",
    "#Returns 0 values (%)\n",
    "\n",
    "def get_zeros(df):\n",
    "    zero_dic = {}\n",
    "    for col in df.columns:\n",
    "        if (df[col] == 0).sum() > 0:\n",
    "            zero_dic[col] = (df[col] == 0).sum()\n",
    "    return pd.DataFrame({'Feature': list(zero_dic.keys()),\n",
    "                        'Zeros': list(zero_dic.values()),\n",
    "                        'Percent': np.round((np.array(list(zero_dic.values())) / df.shape[0])*100, decimals = 1)\n",
    "    }).sort_values('Zeros',ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j5hGtyMsFm0i"
   },
   "outputs": [],
   "source": [
    "train_data =pd.read_csv('train.csv', delimiter=',')\n",
    "test_data  =pd.read_csv('test.csv', delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4eO_HtU3Fm0k"
   },
   "outputs": [],
   "source": [
    "test_data  = test_data.loc[:, (test_data  != 0).any(axis=0)]\n",
    "# Create an column representing the target and assign negative value in order to facilitate the split\n",
    "test_data['NU_NOTA_MT'] = -148\n",
    "train_data = train_data.loc[:, test_data.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My ideia was to concat the two data sets in order to make easy apply the preprocessing techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dfMRTGbIFm0m"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NU_INSCRICAO</th>\n",
       "      <th>CO_UF_RESIDENCIA</th>\n",
       "      <th>SG_UF_RESIDENCIA</th>\n",
       "      <th>NU_IDADE</th>\n",
       "      <th>TP_SEXO</th>\n",
       "      <th>TP_COR_RACA</th>\n",
       "      <th>TP_NACIONALIDADE</th>\n",
       "      <th>TP_ST_CONCLUSAO</th>\n",
       "      <th>TP_ANO_CONCLUIU</th>\n",
       "      <th>TP_ESCOLA</th>\n",
       "      <th>...</th>\n",
       "      <th>NU_NOTA_REDACAO</th>\n",
       "      <th>Q001</th>\n",
       "      <th>Q002</th>\n",
       "      <th>Q006</th>\n",
       "      <th>Q024</th>\n",
       "      <th>Q025</th>\n",
       "      <th>Q026</th>\n",
       "      <th>Q027</th>\n",
       "      <th>Q047</th>\n",
       "      <th>NU_NOTA_MT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73ff9fcc02f0a99919906c942c2e1a1042cdcf98</td>\n",
       "      <td>41</td>\n",
       "      <td>PR</td>\n",
       "      <td>22</td>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>420.0</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>-148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71a95f9f1b91a82c65ad94abbdf9f54e6066f968</td>\n",
       "      <td>21</td>\n",
       "      <td>MA</td>\n",
       "      <td>26</td>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>580.0</td>\n",
       "      <td>E</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>-148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b38a03232f43b11c9d0788abaf060f7366053b6d</td>\n",
       "      <td>23</td>\n",
       "      <td>CE</td>\n",
       "      <td>21</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>320.0</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>-148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70b682d9a3636be23f6120fa9d6b164eb3c6002d</td>\n",
       "      <td>15</td>\n",
       "      <td>PA</td>\n",
       "      <td>27</td>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H</td>\n",
       "      <td>E</td>\n",
       "      <td>G</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>-148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>715494628a50142ce8cb17191cfe6d0f3cae0934</td>\n",
       "      <td>41</td>\n",
       "      <td>PR</td>\n",
       "      <td>18</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>320.0</td>\n",
       "      <td>D</td>\n",
       "      <td>H</td>\n",
       "      <td>H</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>-148.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               NU_INSCRICAO  CO_UF_RESIDENCIA  \\\n",
       "0  73ff9fcc02f0a99919906c942c2e1a1042cdcf98                41   \n",
       "1  71a95f9f1b91a82c65ad94abbdf9f54e6066f968                21   \n",
       "2  b38a03232f43b11c9d0788abaf060f7366053b6d                23   \n",
       "3  70b682d9a3636be23f6120fa9d6b164eb3c6002d                15   \n",
       "4  715494628a50142ce8cb17191cfe6d0f3cae0934                41   \n",
       "\n",
       "  SG_UF_RESIDENCIA  NU_IDADE TP_SEXO  TP_COR_RACA  TP_NACIONALIDADE  \\\n",
       "0               PR        22       F            3                 1   \n",
       "1               MA        26       F            3                 1   \n",
       "2               CE        21       M            1                 1   \n",
       "3               PA        27       F            3                 1   \n",
       "4               PR        18       M            1                 1   \n",
       "\n",
       "   TP_ST_CONCLUSAO  TP_ANO_CONCLUIU  TP_ESCOLA  ...  NU_NOTA_REDACAO  Q001  \\\n",
       "0                1                5          1  ...            420.0     B   \n",
       "1                1                8          1  ...            580.0     E   \n",
       "2                2                0          2  ...            320.0     E   \n",
       "3                1                8          1  ...              NaN     H   \n",
       "4                2                0          2  ...            320.0     D   \n",
       "\n",
       "   Q002  Q006  Q024  Q025  Q026  Q027  Q047  NU_NOTA_MT  \n",
       "0     A     C     A     A     C     C     A      -148.0  \n",
       "1     B     C     B     B     B     F     A      -148.0  \n",
       "2     E     D     B     B     A   NaN     A      -148.0  \n",
       "3     E     G     B     B     A   NaN     A      -148.0  \n",
       "4     H     H     C     B     A   NaN     A      -148.0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = [test_data,train_data]\n",
    "df = pd.concat(frames)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SNoi-rgmFm0r"
   },
   "outputs": [],
   "source": [
    "#CO_UF_RESIDENCIA and SG_UF_RESIDENCIA represent the same information, the state's code, so we drop one of them\n",
    "df.drop(['SG_UF_RESIDENCIA'], axis = 1, inplace = True)\n",
    "\n",
    "#Define NaN values in target as 0\n",
    "\n",
    "for i in ['NU_NOTA_MT']:\n",
    "    df[i].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8g8VY6e-Fm0u"
   },
   "outputs": [],
   "source": [
    "#Set categorical features as \"category\" dtype and get cat codes, before assigning the mode of columns to NaN values\n",
    "\n",
    "for i in ['CO_PROVA_CN','CO_PROVA_MT', 'CO_PROVA_LC', 'CO_PROVA_CH', 'Q001', 'Q002','Q006','Q024','Q025','Q026','Q027','Q047','TP_SEXO']:\n",
    "    df[i] = df[i].fillna(df[i].mode()[0])\n",
    "    df[i] = df[i].astype('category')\n",
    "    df[i] = df[i].cat.codes\n",
    "\n",
    "#The remaining columns we replace NaN by median\n",
    "df.fillna(df.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "id": "4mkDu4wYEwS1",
    "outputId": "251fcd42-85e3-48ce-c1c7-0b3d8faf2c5d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NU_INSCRICAO</th>\n",
       "      <th>CO_UF_RESIDENCIA</th>\n",
       "      <th>NU_IDADE</th>\n",
       "      <th>TP_SEXO</th>\n",
       "      <th>TP_COR_RACA</th>\n",
       "      <th>TP_NACIONALIDADE</th>\n",
       "      <th>TP_ST_CONCLUSAO</th>\n",
       "      <th>TP_ANO_CONCLUIU</th>\n",
       "      <th>TP_ESCOLA</th>\n",
       "      <th>TP_ENSINO</th>\n",
       "      <th>...</th>\n",
       "      <th>NU_NOTA_REDACAO</th>\n",
       "      <th>Q001</th>\n",
       "      <th>Q002</th>\n",
       "      <th>Q006</th>\n",
       "      <th>Q024</th>\n",
       "      <th>Q025</th>\n",
       "      <th>Q026</th>\n",
       "      <th>Q027</th>\n",
       "      <th>Q047</th>\n",
       "      <th>NU_NOTA_MT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73ff9fcc02f0a99919906c942c2e1a1042cdcf98</td>\n",
       "      <td>41</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>420.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71a95f9f1b91a82c65ad94abbdf9f54e6066f968</td>\n",
       "      <td>21</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>580.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>-148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b38a03232f43b11c9d0788abaf060f7366053b6d</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>320.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>-148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70b682d9a3636be23f6120fa9d6b164eb3c6002d</td>\n",
       "      <td>15</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>540.0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>-148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>715494628a50142ce8cb17191cfe6d0f3cae0934</td>\n",
       "      <td>41</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>320.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>-148.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               NU_INSCRICAO  CO_UF_RESIDENCIA  NU_IDADE  \\\n",
       "0  73ff9fcc02f0a99919906c942c2e1a1042cdcf98                41        22   \n",
       "1  71a95f9f1b91a82c65ad94abbdf9f54e6066f968                21        26   \n",
       "2  b38a03232f43b11c9d0788abaf060f7366053b6d                23        21   \n",
       "3  70b682d9a3636be23f6120fa9d6b164eb3c6002d                15        27   \n",
       "4  715494628a50142ce8cb17191cfe6d0f3cae0934                41        18   \n",
       "\n",
       "   TP_SEXO  TP_COR_RACA  TP_NACIONALIDADE  TP_ST_CONCLUSAO  TP_ANO_CONCLUIU  \\\n",
       "0        0            3                 1                1                5   \n",
       "1        0            3                 1                1                8   \n",
       "2        1            1                 1                2                0   \n",
       "3        0            3                 1                1                8   \n",
       "4        1            1                 1                2                0   \n",
       "\n",
       "   TP_ESCOLA  TP_ENSINO  ...  NU_NOTA_REDACAO  Q001  Q002  Q006  Q024  Q025  \\\n",
       "0          1        1.0  ...            420.0     1     0     2     0     0   \n",
       "1          1        1.0  ...            580.0     4     1     2     1     1   \n",
       "2          2        3.0  ...            320.0     4     4     3     1     1   \n",
       "3          1        1.0  ...            540.0     7     4     6     1     1   \n",
       "4          2        1.0  ...            320.0     3     7     7     2     1   \n",
       "\n",
       "   Q026  Q027  Q047  NU_NOTA_MT  \n",
       "0     2     2     0      -148.0  \n",
       "1     1     5     0      -148.0  \n",
       "2     0     5     0      -148.0  \n",
       "3     0     5     0      -148.0  \n",
       "4     0     5     0      -148.0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7woCC78mFm00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18306, 184)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate de the features we want do apply dummy\n",
    "\n",
    "cat = set(df.columns)-set(['NU_INSCRICAO', 'NU_NOTA_COMP5', 'NU_NOTA_COMP3','NU_NOTA_COMP4','NU_NOTA_COMP1','NU_NOTA_REDACAO', 'Q001', 'Q002','Q006','Q024','Q025','Q026','Q027','Q047','NU_NOTA_COMP2','NU_NOTA_MT','NU_NOTA_LC','NU_NOTA_CN','NU_NOTA_CH'])\n",
    "df = pd.get_dummies(df, columns=cat, drop_first=True)\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "m-0tkniRFm04",
    "outputId": "49682d1d-68e4-4569-bee4-5d72d8a176bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13730, 184) (4576, 184)\n"
     ]
    }
   ],
   "source": [
    "# Split out data set by the value we put in test data, -148\n",
    "\n",
    "train = df.loc[df['NU_NOTA_MT'] != -148]\n",
    "test =  df.loc[df['NU_NOTA_MT'] == -148]\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o9hkMdk9Fm07"
   },
   "outputs": [],
   "source": [
    "#Apply standard scaler to (original)\n",
    "\n",
    "train = train.drop(['NU_INSCRICAO'], axis=1)\n",
    "y = train['NU_NOTA_MT'].copy()\n",
    "X = train.drop(['NU_NOTA_MT'], axis=1)\n",
    "\n",
    "names = X.columns\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaled_df = scaler.fit_transform(X)\n",
    "X = pd.DataFrame(scaled_df, columns=names)\n",
    "\n",
    "#Apply standard scaler to test (the one provided)\n",
    "\n",
    "test_1= test.drop(['NU_INSCRICAO'], axis=1)\n",
    "X_test = test_1.drop(['NU_NOTA_MT'], axis=1)\n",
    "scaled_df_test = scaler.fit_transform(X_test)\n",
    "X_test = pd.DataFrame(scaled_df_test, columns=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ttnRkZXwFm09",
    "outputId": "f36bdcaa-a48d-4fd1-e8c0-110dcde731a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test (9611, 182) (9611,)\n",
      "train (4119, 182) (4119,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print('test',X_train.shape, y_train.shape)\n",
    "print('train',X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NeauQh3opPpo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 182 features.\n",
      "Fitting estimator with 181 features.\n",
      "Fitting estimator with 180 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 178 features.\n",
      "Fitting estimator with 177 features.\n",
      "Fitting estimator with 176 features.\n",
      "Fitting estimator with 175 features.\n",
      "Fitting estimator with 174 features.\n",
      "Fitting estimator with 173 features.\n",
      "Fitting estimator with 172 features.\n",
      "Fitting estimator with 171 features.\n",
      "Fitting estimator with 170 features.\n",
      "Fitting estimator with 169 features.\n",
      "Fitting estimator with 168 features.\n",
      "Fitting estimator with 167 features.\n",
      "Fitting estimator with 166 features.\n",
      "Fitting estimator with 165 features.\n",
      "Fitting estimator with 164 features.\n",
      "Fitting estimator with 163 features.\n",
      "Fitting estimator with 162 features.\n",
      "Fitting estimator with 161 features.\n",
      "Fitting estimator with 160 features.\n",
      "Fitting estimator with 159 features.\n",
      "Fitting estimator with 158 features.\n",
      "Fitting estimator with 157 features.\n",
      "Fitting estimator with 156 features.\n",
      "Fitting estimator with 155 features.\n",
      "Fitting estimator with 154 features.\n",
      "Fitting estimator with 153 features.\n",
      "Fitting estimator with 152 features.\n",
      "Fitting estimator with 151 features.\n",
      "Fitting estimator with 150 features.\n",
      "Fitting estimator with 149 features.\n",
      "Fitting estimator with 148 features.\n",
      "Fitting estimator with 147 features.\n",
      "Fitting estimator with 146 features.\n",
      "Fitting estimator with 145 features.\n",
      "Fitting estimator with 144 features.\n",
      "Fitting estimator with 143 features.\n",
      "Fitting estimator with 142 features.\n",
      "Fitting estimator with 141 features.\n",
      "Fitting estimator with 140 features.\n",
      "Fitting estimator with 139 features.\n",
      "Fitting estimator with 138 features.\n",
      "Fitting estimator with 137 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 135 features.\n",
      "Fitting estimator with 134 features.\n",
      "Fitting estimator with 133 features.\n",
      "Fitting estimator with 132 features.\n",
      "Fitting estimator with 131 features.\n",
      "Fitting estimator with 130 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 128 features.\n",
      "Fitting estimator with 127 features.\n",
      "Fitting estimator with 126 features.\n",
      "Fitting estimator with 125 features.\n",
      "Fitting estimator with 124 features.\n",
      "Fitting estimator with 123 features.\n",
      "Fitting estimator with 122 features.\n",
      "Fitting estimator with 121 features.\n",
      "Fitting estimator with 120 features.\n",
      "Fitting estimator with 119 features.\n",
      "Fitting estimator with 118 features.\n",
      "Fitting estimator with 117 features.\n",
      "Fitting estimator with 116 features.\n",
      "Fitting estimator with 115 features.\n",
      "Fitting estimator with 114 features.\n",
      "Fitting estimator with 113 features.\n",
      "Fitting estimator with 112 features.\n",
      "Fitting estimator with 111 features.\n",
      "Fitting estimator with 110 features.\n",
      "Fitting estimator with 109 features.\n",
      "Fitting estimator with 108 features.\n",
      "Fitting estimator with 107 features.\n",
      "Fitting estimator with 106 features.\n",
      "Fitting estimator with 105 features.\n",
      "Fitting estimator with 104 features.\n",
      "Fitting estimator with 103 features.\n",
      "Fitting estimator with 102 features.\n",
      "Fitting estimator with 101 features.\n",
      "Fitting estimator with 100 features.\n",
      "Fitting estimator with 99 features.\n",
      "Fitting estimator with 98 features.\n",
      "Fitting estimator with 97 features.\n",
      "Fitting estimator with 96 features.\n",
      "Fitting estimator with 95 features.\n",
      "Fitting estimator with 94 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 92 features.\n",
      "Fitting estimator with 91 features.\n",
      "Fitting estimator with 90 features.\n",
      "Fitting estimator with 89 features.\n",
      "Fitting estimator with 88 features.\n",
      "Fitting estimator with 87 features.\n",
      "Fitting estimator with 86 features.\n",
      "Fitting estimator with 85 features.\n",
      "Fitting estimator with 84 features.\n",
      "Fitting estimator with 83 features.\n",
      "Fitting estimator with 82 features.\n",
      "Fitting estimator with 81 features.\n",
      "Fitting estimator with 80 features.\n",
      "Fitting estimator with 79 features.\n",
      "Fitting estimator with 78 features.\n",
      "Fitting estimator with 77 features.\n",
      "Fitting estimator with 76 features.\n",
      "Fitting estimator with 75 features.\n",
      "Fitting estimator with 74 features.\n",
      "Fitting estimator with 73 features.\n",
      "Fitting estimator with 72 features.\n",
      "Fitting estimator with 71 features.\n",
      "Fitting estimator with 70 features.\n",
      "Fitting estimator with 69 features.\n",
      "Fitting estimator with 68 features.\n",
      "Fitting estimator with 67 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 65 features.\n",
      "Fitting estimator with 64 features.\n",
      "Fitting estimator with 63 features.\n",
      "Fitting estimator with 62 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 60 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 58 features.\n",
      "Fitting estimator with 57 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 55 features.\n",
      "Fitting estimator with 54 features.\n",
      "Fitting estimator with 53 features.\n",
      "Fitting estimator with 52 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 48 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 45 features.\n",
      "Fitting estimator with 44 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 42 features.\n",
      "Fitting estimator with 41 features.\n",
      "Fitting estimator with 40 features.\n",
      "Numero otimo de Features :  39\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Feature ranking with recursive feature elimination and cross-validated selection of the best number of features.\n",
    "\n",
    "clf1 = XGBRegressor()\n",
    "rfecv = RFECV(estimator=clf1, step=1, cv=5,scoring='neg_mean_squared_error', n_jobs=4,verbose=1)\n",
    "rfecv = rfecv.fit(X_train,y_train)\n",
    "\n",
    "print('Numero otimo de Features : ', rfecv.n_features_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3PEscUbaDRlu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal number of features is 39\n",
      "The selected features are:\n",
      "['NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_REDACAO', 'Q002', 'Q006', 'Q024', 'Q026', 'Q027', 'Q047', 'TP_COR_RACA_1', 'TP_COR_RACA_4', 'TP_ANO_CONCLUIU_1', 'TP_ANO_CONCLUIU_7', 'TP_ENSINO_3.0', 'NU_IDADE_26', 'NU_IDADE_30', 'NU_IDADE_45', 'NU_IDADE_58', 'CO_PROVA_CN_2', 'CO_PROVA_CN_3', 'CO_PROVA_CN_5', 'TP_PRESENCA_LC_1', 'TP_DEPENDENCIA_ADM_ESC_2.0', 'TP_SEXO_1', 'CO_PROVA_LC_1', 'CO_PROVA_LC_6', 'CO_PROVA_LC_7', 'CO_UF_RESIDENCIA_15', 'CO_UF_RESIDENCIA_16', 'CO_UF_RESIDENCIA_21', 'CO_UF_RESIDENCIA_22', 'CO_UF_RESIDENCIA_25', 'CO_UF_RESIDENCIA_31', 'CO_UF_RESIDENCIA_32', 'CO_UF_RESIDENCIA_41', 'CO_UF_RESIDENCIA_53', 'IN_SABATISTA_1', 'CO_PROVA_MT_7']\n",
      "Out of sample auc: 0.9226998259779099\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('The optimal number of features is {}'.format(rfecv.n_features_))\n",
    "features = [f for f,s in zip(X_train.columns, rfecv.support_) if s]\n",
    "print('The selected features are:')\n",
    "print ('{}'.format(features))\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (roc auc)\")\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "plt.savefig('feature_auc_nselected.png', bbox_inches='tight', pad_inches=1)\n",
    "\n",
    "X_train_s = X_train[features]\n",
    "\n",
    "clf1.fit(X_train_s, y_train)\n",
    "\n",
    "X_val_s = X_val[features]\n",
    "print ('Out of sample auc: {}'.format(clf1.score(X_val_s, y_val)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9LQiZP_ZFm1E"
   },
   "outputs": [],
   "source": [
    "def Grid_Search_CV_RFR(X_train, y_train):\n",
    "    estimator = RandomForestRegressor()\n",
    "    param_grid = { \n",
    "            \"max_depth\"         : [ 5, 10, 15, 20, 30],\n",
    "            \"n_estimators\"      : [8, 16, 32, 64, 100],\n",
    "            \"max_features\"      : [\"auto\", \"sqrt\", \"log2\"],\n",
    "            \"min_samples_split\" : [4,8,12],\n",
    "            \"bootstrap\": [True, False],\n",
    "            }\n",
    "\n",
    "    grid = GridSearchCV(estimator, param_grid, n_jobs=-1, cv=5, verbose = 3)\n",
    "\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    return grid.best_score_ , grid.best_params_\n",
    "\n",
    "def RFR(X_train, X_test, y_train, y_test, best_params):\n",
    "\n",
    "    estimator = RandomForestRegressor(n_jobs=-1).set_params(**best_params)\n",
    "    estimator.fit(X_train,y_train)\n",
    "\n",
    "    y_predict = estimator.predict(X_test)\n",
    "    return y_test,y_predict\n",
    "\n",
    "def splitter_v2(tab,y_indicator):\n",
    "\n",
    "    # Asignamos X e y, eliminando la columna y en X\n",
    "    X = correlacion(tab,y_indicator)\n",
    "    y = tab[:,y_indicator]\n",
    "    # Separamos Train y Test respectivamente para X e y\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "WRSXGy67Fm1G",
    "outputId": "2278073a-f978-44f7-fb30-fd97b7aaff49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop: all features\n",
      "--------------\n",
      "Fitting 5 folds for each of 450 candidates, totalling 2250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   42.2s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 496 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1136 tasks      | elapsed:  9.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1552 tasks      | elapsed: 12.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2032 tasks      | elapsed: 19.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2250 out of 2250 | elapsed: 22.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.9232962851064107\n",
      "Best params: {'bootstrap': True, 'max_depth': 10, 'max_features': 'auto', 'min_samples_split': 8, 'n_estimators': 100}\n",
      "Explained Variance Score 0.929438901044644\n",
      "Max Error: 442.5657146794794\n",
      "Mean Absolute Error: 41.628014112017134\n",
      "Root Mean Squared Error: 61.5996840746597\n",
      "Median Squared Error: 30.485450434613426\n",
      "RÂ² score: 0.9294373450807969\n"
     ]
    }
   ],
   "source": [
    "print (\"Loop: all features\" )\n",
    "print (\"--------------\")\n",
    "\n",
    "best_score, best_params = Grid_Search_CV_RFR(X_train, y_train)\n",
    "y_val , y_pred = RFR(X_train, X_val, y_train, y_val, best_params)\n",
    "print(\"Best Score:\" ,best_score)\n",
    "print(\"Best params:\",best_params)\n",
    "print('Explained Variance Score', explained_variance_score(y_val, y_pred)) \n",
    "#The best possible score is 1.0, lower values are worse.\n",
    "print('Max Error:', (max_error(y_val, y_pred)))\n",
    "# maior real - predito\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_val, y_pred))\n",
    "# MAE = (real - predito) / n, erro mÃ©dio\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_val, y_pred)))\n",
    "# RMSE = raiz do quadrado do anterior\n",
    "print('Median Squared Error:', median_absolute_error(y_val, y_pred))\n",
    "# mediana dos (real - predito)\n",
    "print('RÂ² score:', r2_score(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "WRSXGy67Fm1G",
    "outputId": "2278073a-f978-44f7-fb30-fd97b7aaff49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop: selected features\n",
      "--------------\n",
      "Fitting 5 folds for each of 450 candidates, totalling 2250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:   30.5s\n",
      "[Parallel(n_jobs=-1)]: Done 496 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1136 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1552 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2032 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2250 out of 2250 | elapsed:  8.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.9230413409903271\n",
      "Best params: {'bootstrap': True, 'max_depth': 10, 'max_features': 'auto', 'min_samples_split': 12, 'n_estimators': 100}\n",
      "Explained Variance Score 0.9293524367038593\n",
      "Max Error: 446.4224223962906\n",
      "Mean Absolute Error: 41.65859480902688\n",
      "Root Mean Squared Error: 61.63746670332073\n",
      "Median Squared Error: 29.747938373990053\n",
      "RÂ² score: 0.9293507582663731\n"
     ]
    }
   ],
   "source": [
    "print (\"Loop: selected features\" )\n",
    "print (\"--------------\")\n",
    "\n",
    "best_score, best_params = Grid_Search_CV_RFR(X_train_s, y_train)\n",
    "y_val , y_pred = RFR(X_train_s, X_val_s, y_train, y_val, best_params)\n",
    "print(\"Best Score:\" ,best_score)\n",
    "print(\"Best params:\",best_params)\n",
    "print('Explained Variance Score', explained_variance_score(y_val, y_pred)) \n",
    "#The best possible score is 1.0, lower values are worse.\n",
    "print('Max Error:', (max_error(y_val, y_pred)))\n",
    "# maior real - predito\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_val, y_pred))\n",
    "# MAE = (real - predito) / n, erro mÃ©dio\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_val, y_pred)))\n",
    "# RMSE = raiz do quadrado do anterior\n",
    "print('Median Squared Error:', median_absolute_error(y_val, y_pred))\n",
    "# mediana dos (real - predito)\n",
    "print('RÂ² score:', r2_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "JTcHJc26Fm1I",
    "outputId": "6e297b37-ed11-4fed-8822-c70d20f19b33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 16550.9\tvalid_0's l1: 105.81\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's l2: 7150.84\tvalid_0's l1: 70.4028\n",
      "[3]\tvalid_0's l2: 4773.54\tvalid_0's l1: 55.2389\n",
      "[4]\tvalid_0's l2: 4189.13\tvalid_0's l1: 48.3655\n",
      "[5]\tvalid_0's l2: 4036.99\tvalid_0's l1: 45.1687\n",
      "[6]\tvalid_0's l2: 4037.42\tvalid_0's l1: 43.8172\n",
      "[7]\tvalid_0's l2: 4045.8\tvalid_0's l1: 43.1571\n",
      "[8]\tvalid_0's l2: 4068.82\tvalid_0's l1: 43.2485\n",
      "[9]\tvalid_0's l2: 4086.57\tvalid_0's l1: 43.1531\n",
      "[10]\tvalid_0's l2: 4112.97\tvalid_0's l1: 43.2738\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's l2: 4036.99\tvalid_0's l1: 45.1687\n",
      "Explained Variance Score 0.9249283771746605\n",
      "Max Error: 489.23556790573633\n",
      "Mean Absolute Error: 45.16866567992274\n",
      "Root Mean Squared Error: 63.53732595415729\n",
      "Median Squared Error: 29.066285506710074\n",
      "RÂ² score: 0.9249283762866263\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'l2', 'l1'},\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.5,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
    "\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=20,\n",
    "                valid_sets=lgb_eval,\n",
    "                early_stopping_rounds=5)\n",
    "\n",
    "y_pred = gbm.predict(X_val, num_iteration=gbm.best_iteration)\n",
    "\n",
    "print('Explained Variance Score', explained_variance_score(y_val, y_pred)) \n",
    "#The best possible score is 1.0, lower values are worse.\n",
    "print('Max Error:', (max_error(y_val, y_pred)))\n",
    "# maior real - predito\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_val, y_pred))\n",
    "# MAE = (real - predito) / n, erro mÃ©dio\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_val, y_pred)))\n",
    "# RMSE = raiz do quadrado do anterior\n",
    "print('Median Squared Error:', median_absolute_error(y_val, y_pred))\n",
    "# mediana dos (real - predito)\n",
    "print('RÂ² score:', r2_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 16546.2\tvalid_0's l1: 105.798\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's l2: 7160.38\tvalid_0's l1: 70.4873\n",
      "[3]\tvalid_0's l2: 4788.88\tvalid_0's l1: 55.2405\n",
      "[4]\tvalid_0's l2: 4193.83\tvalid_0's l1: 48.5626\n",
      "[5]\tvalid_0's l2: 4042.96\tvalid_0's l1: 45.3648\n",
      "[6]\tvalid_0's l2: 4020.26\tvalid_0's l1: 43.8485\n",
      "[7]\tvalid_0's l2: 4068.93\tvalid_0's l1: 43.3633\n",
      "[8]\tvalid_0's l2: 4081.44\tvalid_0's l1: 43.0652\n",
      "[9]\tvalid_0's l2: 4100.59\tvalid_0's l1: 43.21\n",
      "[10]\tvalid_0's l2: 4124.53\tvalid_0's l1: 43.3205\n",
      "[11]\tvalid_0's l2: 4113.31\tvalid_0's l1: 43.1398\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's l2: 4020.26\tvalid_0's l1: 43.8485\n",
      "Explained Variance Score 0.9252397183675909\n",
      "Max Error: 466.01389665669683\n",
      "Mean Absolute Error: 43.848499415955324\n",
      "Root Mean Squared Error: 63.40555799036314\n",
      "Median Squared Error: 29.417939605689526\n",
      "RÂ² score: 0.9252394305359057\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'l2', 'l1'},\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.5,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "lgb_train = lgb.Dataset(X_train_s, y_train)\n",
    "lgb_eval = lgb.Dataset(X_val_s, y_val, reference=lgb_train)\n",
    "\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=20,\n",
    "                valid_sets=lgb_eval,\n",
    "                early_stopping_rounds=5)\n",
    "\n",
    "y_pred = gbm.predict(X_val_s, num_iteration=gbm.best_iteration)\n",
    "\n",
    "print('Explained Variance Score', explained_variance_score(y_val, y_pred)) \n",
    "#The best possible score is 1.0, lower values are worse.\n",
    "print('Max Error:', (max_error(y_val, y_pred)))\n",
    "# maior real - predito\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_val, y_pred))\n",
    "# MAE = (real - predito) / n, erro mÃ©dio\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_val, y_pred)))\n",
    "# RMSE = raiz do quadrado do anterior\n",
    "print('Median Squared Error:', median_absolute_error(y_val, y_pred))\n",
    "# mediana dos (real - predito)\n",
    "print('RÂ² score:', r2_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "YveC_4EHFm1K",
    "outputId": "0732d0fa-074e-4a27-e0c6-6a80232e728c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:04:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[01:05:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Explained Variance Score 0.926442334950738\n",
      "Max Error: 452.886474609375\n",
      "Mean Absolute Error: 42.73003743191198\n",
      "Root Mean Squared Error: 62.89345758388808\n",
      "Median Squared Error: 29.054174804687477\n",
      "RÂ² score: 0.9264421740654549\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection \n",
    "\n",
    "model = XGBRegressor(max_depth = 5,\n",
    "                   learning_rate = 0.05,\n",
    "                   n_estimators = 500,\n",
    "                   n_jobs = 5,\n",
    "                   subsample= 0.25,\n",
    "                   min_child_weight=1,\n",
    "                     objective = 'reg:linear',\n",
    "                   colsample_bytree=1\n",
    "                   \n",
    "                  )\n",
    "splits = 5\n",
    "folds = model_selection.KFold(n_splits=splits)\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "print('Explained Variance Score', explained_variance_score(y_val, y_pred)) \n",
    "#The best possible score is 1.0, lower values are worse.\n",
    "print('Max Error:', (max_error(y_val, y_pred)))\n",
    "# maior real - predito\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_val, y_pred))\n",
    "# MAE = (real - predito) / n, erro mÃ©dio\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_val, y_pred)))\n",
    "# RMSE = raiz do quadrado do anterior\n",
    "print('Median Squared Error:', median_absolute_error(y_val, y_pred))\n",
    "# mediana dos (real - predito)\n",
    "print('RÂ² score:', r2_score(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "869xZeCuScqK",
    "outputId": "1cbe7400-6215-4e13-ee4b-641322d71629"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Score 0.9300667825542721\n",
      "Max Error: 435.914306640625\n",
      "Mean Absolute Error: 41.767770460231354\n",
      "Root Mean Squared Error: 61.3730796108229\n",
      "Median Squared Error: 28.770889282226562\n",
      "RÂ² score: 0.9299555426092607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Venicius Ferreira\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  30 out of  30 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:06:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[01:06:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Explained Variance Score 0.930605865931951\n",
      "Max Error: 448.4122009277344\n",
      "Mean Absolute Error: 42.14896968985304\n",
      "Root Mean Squared Error: 61.08844767083316\n",
      "Median Squared Error: 28.859472656249977\n",
      "RÂ² score: 0.9306037309985555\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBRegressor(max_depth = 3,\n",
    "                   learning_rate = 0.05,\n",
    "                   n_estimators = 100,\n",
    "                   n_jobs = 5,\n",
    "                   subsample=0.5213,\n",
    "                   min_child_weight=1.7817,\n",
    "                   reg_alpha=0.4640,\n",
    "                   reg_lambda=0.8571,\n",
    "                   gamma=0.0468,\n",
    "                   colsample_bytree=0.4603\n",
    "                   \n",
    "                  )\n",
    "xgb.fit(X_train,y_train)\n",
    "y_pred = xgb.predict(X_val)\n",
    "from sklearn.metrics import explained_variance_score, max_error, mean_absolute_error, mean_squared_error,median_absolute_error, r2_score\n",
    "\n",
    "print('Explained Variance Score', explained_variance_score(y_val, y_pred)) \n",
    "#The best possible score is 1.0, lower values are worse.\n",
    "print('Max Error:', (max_error(y_val, y_pred)))\n",
    "# maior real - predito\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_val, y_pred))\n",
    "# MAE = (real - predito) / n, erro mÃ©dio\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_val, y_pred)))\n",
    "# RMSE = raiz do quadrado do anterior\n",
    "print('Median Squared Error:', median_absolute_error(y_val, y_pred))\n",
    "# mediana dos (real - predito)\n",
    "print('RÂ² score:', r2_score(y_val, y_pred))\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "parameters = {'objective':['reg:linear'],\n",
    "              'learning_rate': [0.1, 0.2, 0.5, 0.05],\n",
    "              'max_depth': [2,3,4,5,6,7],\n",
    "              'min_child_weight': [0.5,1],\n",
    "              'subsample': [0.25,0.5,1],\n",
    "              'colsample_bytree': [0.5,1],\n",
    "              'n_estimators': [50, 100, 200, 300, 500]}\n",
    "\n",
    "rs = RandomizedSearchCV (estimator= xgb,\n",
    "                        param_distributions= parameters,\n",
    "                        scoring = 'neg_mean_squared_error',\n",
    "                        n_jobs= 5,verbose=1,\n",
    "                        n_iter = 10)\n",
    "\n",
    "rs_result = rs.fit(X_train,y_train)\n",
    "y_pred = rs_result.predict(X_val)\n",
    "from sklearn.metrics import explained_variance_score, max_error, mean_absolute_error, mean_squared_error,median_absolute_error, r2_score\n",
    "\n",
    "print('Explained Variance Score', explained_variance_score(y_val, y_pred)) \n",
    "#The best possible score is 1.0, lower values are worse.\n",
    "print('Max Error:', (max_error(y_val, y_pred)))\n",
    "# maior real - predito\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_val, y_pred))\n",
    "# MAE = (real - predito) / n, erro mÃ©dio\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_val, y_pred)))\n",
    "# RMSE = raiz do quadrado do anterior\n",
    "print('Median Squared Error:', median_absolute_error(y_val, y_pred))\n",
    "# mediana dos (real - predito)\n",
    "print('RÂ² score:', r2_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Score 0.9281822238193368\n",
      "Max Error: 444.0349426269531\n",
      "Mean Absolute Error: 42.61930843139627\n",
      "Root Mean Squared Error: 62.19299801479192\n",
      "Median Squared Error: 31.63154296875001\n",
      "RÂ² score: 0.9280715125008849\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Venicius Ferreira\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  30 out of  30 | elapsed:   32.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:07:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[01:07:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:168: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Explained Variance Score 0.9288949395072128\n",
      "Max Error: 441.46221923828125\n",
      "Mean Absolute Error: 42.03463753442591\n",
      "Root Mean Squared Error: 61.83607169736092\n",
      "Median Squared Error: 29.063861083984364\n",
      "RÂ² score: 0.9288947402490864\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBRegressor(max_depth = 3,\n",
    "                   learning_rate = 0.05,\n",
    "                   n_estimators = 100,\n",
    "                   n_jobs = 5,\n",
    "                   subsample=0.5213,\n",
    "                   min_child_weight=1.7817,\n",
    "                   reg_alpha=0.4640,\n",
    "                   reg_lambda=0.8571,\n",
    "                   gamma=0.0468,\n",
    "                   colsample_bytree=0.4603\n",
    "                   \n",
    "                  )\n",
    "xgb.fit(X_train_s,y_train)\n",
    "y_pred = xgb.predict(X_val_s)\n",
    "from sklearn.metrics import explained_variance_score, max_error, mean_absolute_error, mean_squared_error,median_absolute_error, r2_score\n",
    "\n",
    "print('Explained Variance Score', explained_variance_score(y_val, y_pred)) \n",
    "#The best possible score is 1.0, lower values are worse.\n",
    "print('Max Error:', (max_error(y_val, y_pred)))\n",
    "# maior real - predito\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_val, y_pred))\n",
    "# MAE = (real - predito) / n, erro mÃ©dio\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_val, y_pred)))\n",
    "# RMSE = raiz do quadrado do anterior\n",
    "print('Median Squared Error:', median_absolute_error(y_val, y_pred))\n",
    "# mediana dos (real - predito)\n",
    "print('RÂ² score:', r2_score(y_val, y_pred))\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "parameters = {'objective':['reg:linear'],\n",
    "              'learning_rate': [0.1, 0.2, 0.5, 0.05],\n",
    "              'max_depth': [2,3,4,5,6,7],\n",
    "              'min_child_weight': [0.5,1],\n",
    "              'subsample': [0.25,0.5,1],\n",
    "              'colsample_bytree': [0.5,1],\n",
    "              'n_estimators': [50, 100, 200, 300, 500]}\n",
    "\n",
    "rs = RandomizedSearchCV (estimator= xgb,\n",
    "                        param_distributions= parameters,\n",
    "                        scoring = 'neg_mean_squared_error',\n",
    "                        n_jobs= 5,verbose=1,\n",
    "                        n_iter = 10)\n",
    "\n",
    "rs_result = rs.fit(X_train_s,y_train)\n",
    "y_pred = rs_result.predict(X_val_s)\n",
    "from sklearn.metrics import explained_variance_score, max_error, mean_absolute_error, mean_squared_error,median_absolute_error, r2_score\n",
    "\n",
    "print('Explained Variance Score', explained_variance_score(y_val, y_pred)) \n",
    "#The best possible score is 1.0, lower values are worse.\n",
    "print('Max Error:', (max_error(y_val, y_pred)))\n",
    "# maior real - predito\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_val, y_pred))\n",
    "# MAE = (real - predito) / n, erro mÃ©dio\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_val, y_pred)))\n",
    "# RMSE = raiz do quadrado do anterior\n",
    "print('Median Squared Error:', median_absolute_error(y_val, y_pred))\n",
    "# mediana dos (real - predito)\n",
    "print('RÂ² score:', r2_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "modelo-v2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
